import streamlit as st
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
import matplotlib

# =========================
# è¨­å®š
# =========================
SVM_THRESHOLD = 0.62
LOGI_THRESHOLD = 0.5

st.set_page_config(page_title="å›ºåŒ–äºˆæ¸¬ã‚¢ãƒ—ãƒª", layout="centered")
st.title("ğŸ§ª å›ºåŒ–äºˆæ¸¬ã‚¢ãƒ—ãƒª")

# =========================
# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆå¯¾å¿œ
# =========================
matplotlib.rcParams["font.family"] = "Yu Gothic"

# =========================
# ãƒ¢ãƒ‡ãƒ«ãƒ»ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼èª­ã¿è¾¼ã¿
# =========================
with open("scaler.pkl", "rb") as f:
    scaler = pickle.load(f)
with open("logistic_model.pkl", "rb") as f:
    logi = pickle.load(f)
with open("svm_model.pkl", "rb") as f:
    svm = pickle.load(f)
with open("feature_columns.pkl", "rb") as f:
    feature_cols = pickle.load(f)

# =========================
# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¨™æº–åŒ–å¾Œãƒ»è©•ä¾¡ç”¨ï¼‰
# =========================
file_path_scaled = "ãƒã‚¤ã‚½ãƒªP_PAW_PWH_final_MI_r3 - ã‚³ãƒ”ãƒ¼ - ã‚³ãƒ”ãƒ¼.csv"
df_scaled = pd.read_csv(file_path_scaled, encoding="utf-8")  # UTF-8
target_col = "å›ºåŒ–"
# ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ç”¨ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¨™æº–åŒ–å‰CSVã‚’ä½¿ç”¨ï¼‰
file_path_eval = "ãƒã‚¤ã‚½ãƒªP_PAW_PWH_final_MI_r3 _å¤§å…ƒ.csv"
df_eval = pd.read_csv(file_path_eval, encoding="utf-8")
X_eval = df_eval[feature_cols].select_dtypes(include=[float, int])
y_eval = df_eval[target_col]

# æ¨™æº–åŒ–
X_eval_scaled = scaler.transform(X_eval)



# =========================
# æ¨™æº–åŒ–å‰ãƒ‡ãƒ¼ã‚¿ï¼ˆä»£è¡¨å€¤ç”¨ï¼‰
# =========================
file_path_orig = "ãƒã‚¤ã‚½ãƒªP_PAW_PWH_final_MI_r3 _å¤§å…ƒ.csv"
df_orig = pd.read_csv(file_path_orig, encoding="utf-8")
X_orig = df_orig[feature_cols].select_dtypes(include=[float, int])
X_mean_orig = X_orig.mean()  # æ¨™æº–åŒ–å‰ã®å¹³å‡å€¤

# =========================
# ã‚¿ãƒ–ä½œæˆ
# =========================
tab1, tab2 = st.tabs(["å›ºåŒ–äºˆæ¸¬", "ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"])

# =========================
# ã‚¿ãƒ–1: å›ºåŒ–äºˆæ¸¬
# =========================
with tab1:
    st.subheader("ç‰¹å¾´é‡å…¥åŠ›ã§å›ºåŒ–äºˆæ¸¬")

    # ã€Œä»£è¡¨å€¤ã«ãƒªã‚»ãƒƒãƒˆã€ãƒœã‚¿ãƒ³
    if st.button("å…¥åŠ›å€¤ã‚’ä»£è¡¨å€¤ã«ãƒªã‚»ãƒƒãƒˆ", key="reset_mean"):
        input_values = X_mean_orig.to_dict()
    else:
        input_values = {col: st.number_input(col, value=X_mean_orig[col]) for col in feature_cols}

    input_df = pd.DataFrame([input_values])

    # ãƒ¢ãƒ‡ãƒ«å…¥åŠ›ç”¨ã«æ¨™æº–åŒ–
    X_input_scaled = scaler.transform(input_df[feature_cols])

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    model_type = st.radio(
        "è§£æãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°", "SVMï¼ˆRBFï¼‰"]
    )

    if st.button("äºˆæ¸¬", key="predict"):
        if model_type == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
            proba = logi.predict_proba(X_input_scaled)[0, 1]
            threshold = LOGI_THRESHOLD
        else:
            proba = svm.predict_proba(X_input_scaled)[0, 1]
            threshold = SVM_THRESHOLD

        pred = int(proba >= threshold)

        st.metric("å›ºåŒ–ç¢ºç‡", f"{proba:.3f}")
        if pred == 1:
            st.error("å›ºåŒ–ã¨äºˆæ¸¬")
        else:
            st.success("éå›ºåŒ–ã¨äºˆæ¸¬")
        st.caption(f"åˆ¤å®šé–¾å€¤: {threshold}")

# =========================
# ã‚¿ãƒ–2: ãƒ¢ãƒ‡ãƒ«è©•ä¾¡
# =========================
with tab2:
    st.subheader("ãƒ¢ãƒ‡ãƒ«ç²¾åº¦è©•ä¾¡ï¼ˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼‰")
    model_type_eval = st.radio(
        "è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠã—ã¦ãã ã•ã„",
        ["ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°", "SVMï¼ˆRBFï¼‰"]
    )

    if st.button("è©•ä¾¡å®Ÿè¡Œ", key="eval"):
        if model_type_eval == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
            y_pred = (logi.predict_proba(X_eval_scaled)[:, 1] >= LOGI_THRESHOLD).astype(int)
        else:
            y_pred = (svm.predict_proba(X_eval_scaled)[:, 1] >= SVM_THRESHOLD).astype(int)


        # ç²¾åº¦è¡¨ç¤º
        acc = accuracy_score(y_eval, y_pred)
        st.write(f"âœ… æ­£è§£ç‡ (Accuracy): {acc:.3f}")

        # æ··åŒè¡Œåˆ—
        cm = confusion_matrix(y_eval, y_pred)
        fig, ax = plt.subplots()
        sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
        ax.set_xlabel("äºˆæ¸¬")
        ax.set_ylabel("å®Ÿéš›")
        st.pyplot(fig)

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆ
        st.text(classification_report(y_eval, y_pred, digits=3))


        # ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ã®ã¿ç‰¹å¾´é‡é‡è¦åº¦
        if model_type_eval == "ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°":
            st.subheader("ç‰¹å¾´é‡é‡è¦åº¦ï¼ˆä¿‚æ•°ï¼‰")
            coef_df = pd.DataFrame({
                "ç‰¹å¾´é‡": feature_cols,
                "é‡è¦åº¦": logi.coef_[0]
            }).sort_values(by="é‡è¦åº¦", key=abs, ascending=False)

            fig2, ax2 = plt.subplots(figsize=(8, max(4, len(feature_cols)*0.3)))
            sns.barplot(x="é‡è¦åº¦", y="ç‰¹å¾´é‡", data=coef_df, ax=ax2, palette="viridis")
            ax2.set_title("ãƒ­ã‚¸ã‚¹ãƒ†ã‚£ãƒƒã‚¯å›å¸°ä¿‚æ•°")
            st.pyplot(fig2)


